from aiofiles import open as aiopen
from aiofiles.os import remove as aioremove, path as aiopath, listdir
from aiohttp import ClientSession
from aioshutil import rmtree as aiormtree, disk_usage
from magic import Magic
from os import walk, path as ospath, makedirs
from re import split as re_split, search as re_search, escape, I
from subprocess import run as srun
from sys import exit as sexit

from bot import aria2, config_dict, get_client, DOWNLOAD_DIR, LOGGER, ARIA_NAME, QBIT_NAME, FFMPEG_NAME
from bot.helper.ext_utils.bot_utils import sync_to_async, async_to_sync, cmd_exec
from bot.helper.ext_utils.exceptions import NotSupportedExtractionArchive


ARCH_EXT = ['.tar.bz2', '.tar.gz', '.bz2', '.gz', '.tar.xz', '.tar', '.tbz2', '.tgz', '.lzma2',
            '.zip', '.7z', '.z', '.rar', '.iso', '.wim', '.cab', '.apm', '.arj', '.chm',
            '.cpio', '.cramfs', '.deb', '.dmg', '.fat', '.hfs', '.lzh', '.lzma', '.mbr',
            '.msi', '.mslz', '.nsis', '.ntfs', '.rpm', '.squashfs', '.udf', '.vhd', '.xar']

FIRST_SPLIT_REGEX = r'(\.|_)part0*1\.rar$|(\.|_)7z\.0*1$|(\.|_)zip\.0*1$|^(?!.*(\.|_)part\d+\.rar$).*\.rar$'

SPLIT_REGEX = r'\.r\d+$|\.7z\.\d+$|\.z\d+$|\.zip\.\d+$'


def is_first_archive_split(file):
    return bool(re_search(FIRST_SPLIT_REGEX, file))


def is_archive(file):
    return file.endswith(tuple(ARCH_EXT))


def is_archive_split(file):
    return bool(re_search(SPLIT_REGEX, file))


async def clean_target(path, log=False):
    if not await aiopath.exists(str(path)):
        return False
    if log:
        LOGGER.info('Cleaning Target: %s', path)
    if await aiopath.isdir(path):
        await aiormtree(path)
    else:
        await aioremove(path)
    return True


async def clean_download(path):
    if await aiopath.exists(path):
        LOGGER.info('Cleaning Download: %s', path)
        await clean_target(path)


def clean_all():
    aria2.remove_all(True)
    get_client().torrents_delete(torrent_hashes='all')
    CURRENT_DIR = config_dict['DOWNLOAD_DIR']
    async_to_sync(clean_target, CURRENT_DIR)
    if DOWNLOAD_DIR != CURRENT_DIR:
        async_to_sync(clean_target, DOWNLOAD_DIR)
    makedirs(DOWNLOAD_DIR, exist_ok=True)


def exit_clean_up(_, __):
    try:
        LOGGER.info('Please wait, while we clean up and stop the running downloads')
        clean_all()
        srun(['pkill', '-9', '-f', f'gunicorn|{ARIA_NAME}|{QBIT_NAME}|{FFMPEG_NAME}|gclone|java|alass'], check=True)
        sexit(0)
    except KeyboardInterrupt:
        LOGGER.warning('Force Exiting before the cleanup finishes!')
        sexit(1)


async def clean_unwanted(path):
    LOGGER.info('Cleaning unwanted files/folders: %s', path)
    for dirpath, _, files in await sync_to_async(walk, path, topdown=False):
        for filee in files:
            if filee.endswith('.!qB') or filee.endswith('.parts') and filee.startswith('.'):
                await clean_target(ospath.join(dirpath, filee))
        if dirpath.endswith(('.unwanted', 'splited_files_mltb', 'copied_mltb')) or not files:
            await clean_target(dirpath)


async def get_path_size(path):
    if await aiopath.isfile(path):
        return await aiopath.getsize(path)
    total_size = 0
    for root, _, files in await sync_to_async(walk, path):
        for f in files:
            abs_path = ospath.join(root, f)
            total_size += await aiopath.getsize(abs_path)
    return total_size


async def count_files_and_folders(path, extensionFilter):
    total_files = total_folders = 0
    for _, dirs, files in await sync_to_async(walk, path):
        total_files += len(files)
        for f in files:
            if f.endswith(tuple(extensionFilter)):
                total_files -= 1
        total_folders += len(dirs)
    return total_folders, total_files


async def check_storage_threshold(size: int, arch=False, alloc=False):
    STORAGE_THRESHOLD, DOWNLOAD_DIR = config_dict['STORAGE_THRESHOLD'], config_dict['DOWNLOAD_DIR']
    if not alloc:
        if not arch:
            if await disk_usage(DOWNLOAD_DIR).free - size < STORAGE_THRESHOLD * 1024**3:
                return False
        elif await disk_usage(DOWNLOAD_DIR).free - (size * 2) < STORAGE_THRESHOLD * 1024**3:
            return False
    elif not arch:
        if await disk_usage(DOWNLOAD_DIR).free < STORAGE_THRESHOLD * 1024**3:
            return False
    elif await disk_usage(DOWNLOAD_DIR).free - size < STORAGE_THRESHOLD * 1024**3:
        return False
    return True


def get_base_name(orig_path):
    extension = next((ext for ext in ARCH_EXT if orig_path.lower().endswith(ext)), '')
    if extension != '':
        return re_split(f'{extension}$', orig_path, maxsplit=1, flags=I)[0]
    raise NotSupportedExtractionArchive('File format not supported for extraction')


def get_mime_type(file_path):
    mime = Magic(mime=True)
    mime_type = mime.from_file(file_path)
    mime_type = mime_type or 'text/plain'
    return mime_type


async def downlod_content(url: str, name: str):
    try:
        async with ClientSession() as session, session.get(url, ssl=False) as r:
            if r.status == 200:
                async for data in r.content.iter_chunked(1024):
                    async with aiopen(name, 'ba') as f:
                        await f.write(data)
                return True
            LOGGER.error('Failed to download %s, got respons %s.', name, r.status)
    except Exception as e:
        LOGGER.error(e)


async def join_files(path):
    files = await listdir(path)
    results = []
    for file_ in files:
        if re_search(r'\.0+2$', file_) and await sync_to_async(get_mime_type, ospath.join(path, file_)) == 'application/octet-stream':
            final_name = file_.rsplit('.', 1)[0]
            fname = ospath.join(path, final_name)
            cmd = f'cat {fname}.* > {fname}'
            _, stderr, code = await cmd_exec(cmd, True)
            if code != 0:
                LOGGER.error('Failed to join %s, stderr: %s', final_name, stderr)
            else:
                results.append(final_name)
        else:
            LOGGER.warning('No Binary files to join!')
    if results:
        LOGGER.info('Join Completed!')
        for res in results:
            for file_ in files:
                if re_search(fr'{escape(res)}\.0[0-9]+$', file_):
                    await aioremove(ospath.join(path, file_))
